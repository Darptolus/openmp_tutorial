{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1: Introduction to OpenMP\n",
    "\n",
    "The objective of this lab is to get familiar with the basic concepts behind OpenMP. Some of these concepts are shared with other programming models, and are important to understand how systems are programmed in parallel. These concepts are introduced directly using OpenMP syntax. It is not expected for the reader to know OpenMP, but they should be familiar with C-like syntax.\n",
    "\n",
    "This tutorial is expected to run in a unix-like environment.\n",
    "\n",
    "## Table of content:\n",
    "\n",
    "* Thread and multithread\n",
    "    * First parallel program\n",
    "    * Thinking in parallel\n",
    "    * Exercise 1\n",
    "* Memory: Shared, private, distributed\n",
    "    * Atomic operations\n",
    "    * Private vs Firstprivate\n",
    "    * Reductions\n",
    "    * Lastprivate\n",
    "    * Exercise 2\n",
    "* OpenMP Syntax\n",
    "* Function outlining, implementation and runtime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thread and multithreads\n",
    "\n",
    "Simply speaking, a thread is a worker that execute instructions. Current CPU architectures are mostly multi threaded, where each worker is independent to each other. \n",
    "\n",
    "Let's see how many cores are in our current system using `lscpu`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecture:                    x86_64\n",
      "CPU op-mode(s):                  32-bit, 64-bit\n",
      "Byte Order:                      Little Endian\n",
      "Address sizes:                   46 bits physical, 48 bits virtual\n",
      "CPU(s):                          48\n",
      "On-line CPU(s) list:             0-47\n",
      "Thread(s) per core:              2\n",
      "Core(s) per socket:              12\n",
      "Socket(s):                       2\n",
      "NUMA node(s):                    2\n",
      "Vendor ID:                       GenuineIntel\n",
      "CPU family:                      6\n",
      "Model:                           85\n",
      "Model name:                      Intel(R) Xeon(R) Gold 6126 CPU @ 2.60GHz\n",
      "Stepping:                        4\n",
      "CPU MHz:                         1000.071\n",
      "CPU max MHz:                     3700.0000\n",
      "CPU min MHz:                     1000.0000\n",
      "BogoMIPS:                        5200.00\n",
      "Virtualization:                  VT-x\n",
      "L1d cache:                       768 KiB\n",
      "L1i cache:                       768 KiB\n",
      "L2 cache:                        24 MiB\n",
      "L3 cache:                        38.5 MiB\n",
      "NUMA node0 CPU(s):               0,2,4,6,8,10,12,14,16,18,20,22,24,26,28,30,32,3\n",
      "                                 4,36,38,40,42,44,46\n",
      "NUMA node1 CPU(s):               1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31,33,3\n",
      "                                 5,37,39,41,43,45,47\n",
      "Vulnerability Itlb multihit:     KVM: Mitigation: Split huge pages\n",
      "Vulnerability L1tf:              Mitigation; PTE Inversion; VMX conditional cach\n",
      "                                 e flushes, SMT vulnerable\n",
      "Vulnerability Mds:               Mitigation; Clear CPU buffers; SMT vulnerable\n",
      "Vulnerability Meltdown:          Mitigation; PTI\n",
      "Vulnerability Spec store bypass: Mitigation; Speculative Store Bypass disabled v\n",
      "                                 ia prctl and seccomp\n",
      "Vulnerability Spectre v1:        Mitigation; usercopy/swapgs barriers and __user\n",
      "                                  pointer sanitization\n",
      "Vulnerability Spectre v2:        Mitigation; Full generic retpoline, IBPB condit\n",
      "                                 ional, IBRS_FW, STIBP conditional, RSB filling\n",
      "Vulnerability Srbds:             Not affected\n",
      "Vulnerability Tsx async abort:   Mitigation; Clear CPU buffers; SMT vulnerable\n",
      "Flags:                           fpu vme de pse tsc msr pae mce cx8 apic sep mtr\n",
      "                                 r pge mca cmov pat pse36 clflush dts acpi mmx f\n",
      "                                 xsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rd\n",
      "                                 tscp lm constant_tsc art arch_perfmon pebs bts \n",
      "                                 rep_good nopl xtopology nonstop_tsc cpuid aperf\n",
      "                                 mperf pni pclmulqdq dtes64 monitor ds_cpl vmx s\n",
      "                                 mx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid d\n",
      "                                 ca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadli\n",
      "                                 ne_timer aes xsave avx f16c rdrand lahf_lm abm \n",
      "                                 3dnowprefetch cpuid_fault epb cat_l3 cdp_l3 inv\n",
      "                                 pcid_single pti intel_ppin ssbd mba ibrs ibpb s\n",
      "                                 tibp tpr_shadow vnmi flexpriority ept vpid ept_\n",
      "                                 ad fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 \n",
      "                                 erms invpcid rtm cqm mpx rdt_a avx512f avx512dq\n",
      "                                  rdseed adx smap clflushopt clwb intel_pt avx51\n",
      "                                 2cd avx512bw avx512vl xsaveopt xsavec xgetbv1 x\n",
      "                                 saves cqm_llc cqm_occup_llc cqm_mbm_total cqm_m\n",
      "                                 bm_local dtherm ida arat pln pts hwp hwp_act_wi\n",
      "                                 ndow hwp_epp hwp_pkg_req pku ospke md_clear flu\n",
      "                                 sh_l1d\n"
     ]
    }
   ],
   "source": [
    "!lscpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the output above you can find the number of CPUs (e.g. 6) and the number of Threads per CPU (e.g. 2). Each Thread is capable of independently handle a different stream of instructions. However, software often creates more threads than available in the hardware system. \n",
    "\n",
    "You can ignore the syntax in the following command, but its output will show the number of threads that are currently running on all the processes in the system (or at leaset those that your user can obtain information about). Most likely you will find that the number of *software* threads is much larger than that of the *hardware* thread. This is because the operating system uses an scheduling scheme to execute all the threads concurrently. \n",
    "\n",
    "The focus of this lab is not to learn about OS threads, but it is worth knowing that the number of *software* threads in a given program can be larger than the number of *hardware* threads running in the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705\n"
     ]
    }
   ],
   "source": [
    "!ps -eo nlwp | tail -n +2 | awk '{ num_threads += $1 } END { print num_threads }'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's create our first threaded program\n",
    "\n",
    "```C\n",
    "#include <omp.h>\n",
    "\n",
    "int main() {\n",
    "    #pragma omp parallel num_threads(10)\n",
    "    {\n",
    "        printf(\"Hello from thread %d\\n\",omp_get_thread_num());\n",
    "    }\n",
    "    return 0;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's compile it\n",
    "!gcc -fopenmp C/parallel.c -o C/parallel.exe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello from thread 2\n",
      "Hello from thread 6\n",
      "Hello from thread 4\n",
      "Hello from thread 7\n",
      "Hello from thread 5\n",
      "Hello from thread 1\n",
      "Hello from thread 9\n",
      "Hello from thread 0\n",
      "Hello from thread 3\n",
      "Hello from thread 8\n"
     ]
    }
   ],
   "source": [
    "# Now it is time to run it.\n",
    "!srun -N 1 ./C/parallel.exe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should immediately notice that (likely) the output of the above program is not in a given order. This is because all the threads are running concurrently, and, if the number of hardware threads is larger than 1, a set of them may be running in parallel.\n",
    "\n",
    "Open the file [parallel.c](C/parallel.c) and play with different number of threads by changing the clause number inside the clause `num_threads()`, and re-running the above two commands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thinking in parallel\n",
    "\n",
    "If you're experienced in sequential programming, you're likely familiar with writing code for a single thread. What a programmer does is to assign the different instructions that modify the memory in order to achieve the desired result. When thinking sequentially, the developer must primarly think of the instructions that are executed. Parallel programming adds an additional complexity to the development program. When writting programs, a developer must think of the following aspects of the code:\n",
    "\n",
    "* **Workers creation**: How to create workers and how many to create\n",
    "* **Work assignment**: How to assign work to different workers\n",
    "* **Workers/resources communication and coordination**: How workers communicate and synchronize in order to coordinate their work.\n",
    "\n",
    "```\n",
    "Note: Different programming models exist that balance these three tasks. Here I am referring to the most popular programming models. Allow me to be simplistic here.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The fork-join model - An example.\n",
    "\n",
    "Although not exclusively, OpenMP is mainly known for its *Fork-Join* model. Programs start with an innitial sequential thread, then code is annotated to initiate parallel threads (workers). Different directives are used to assign work to these threads. At the end of the parallel region, threads synchronize, forming again a single thread.\n",
    "\n",
    "For the above example. **worker creation** is achieved through the `#pragma omp parallel num_threads(10)` directive. It allows to create 10 threads. Each worker is associated with an identifier, obtained through the `omp_get_thread_num()` function call. **Work assignment** is achieved through the code in the region enclosed by the brackets `{...}`. All threads are executing the same set of instructions `printf(\"hello from thread %d\\n\",...);`. Notice that having a different identifier allows for each thread to access different data, or follow different paths. Finally **Worker synchronization and coordination** is relatively simple in this example, since there's not much communication between them. However, at the end of the parallel region, all workers must wait for each other to finish before continuing with the sequential code. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "Can you modify the code above to make the odd and even threads print something different?\n",
    "\n",
    "Go to [exercise1.c](Exercises/exercise1.c) and use the code region below to build and execute your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello from thread 3\n",
      "Hello from thread 0\n",
      "Hello from thread 5\n",
      "Hello from thread 1\n",
      "Hello from thread 9\n",
      "Hello from thread 4\n",
      "Hello from thread 2\n",
      "Hello from thread 6\n",
      "Hello from thread 8\n",
      "Hello from thread 7\n"
     ]
    }
   ],
   "source": [
    "!gcc -fopenmp Exercises/exercise1.c -o Exercises/exercise1.exe && srun -N 1 Exercises/./exercise1.exe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See a [possible solution to Exercise 1](Solutions/exercise1.c)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello from thread 0 I am Odd\n",
      "Hello from thread 1 I am Even\n",
      "Hello from thread 4 I am Odd\n",
      "Hello from thread 2 I am Odd\n",
      "Hello from thread 5 I am Even\n",
      "Hello from thread 9 I am Even\n",
      "Hello from thread 3 I am Even\n",
      "Hello from thread 7 I am Even\n",
      "Hello from thread 6 I am Odd\n",
      "Hello from thread 8 I am Odd\n"
     ]
    }
   ],
   "source": [
    "!gcc -fopenmp Solutions/exercise1.c -o Solutions/exercise1.exe && srun -N 1 Solutions/./exercise1.exe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory: Shared vs Private\n",
    "\n",
    "When programming we often imagine memory as a single \"monolithic\" element. However, this is not the reality. Current architectures feature a complex memory organization that includes registers, caches, multiple DRAM banks, and even devices with a different memory space. When programming in parallel, such complex structures become more important for correctness and performance.\n",
    "\n",
    "Multithreading programming often features shared memory, meaning that all threads have access to the same varibles, located in the same memory address (I expect the reader to be familiar with pointers). However, it is also possible for each thread to have private memory, even if the name of variables are the same.\n",
    "\n",
    "Take for example the next program:\n",
    "\n",
    "```C\n",
    "int main() {\n",
    "    int i;\n",
    "    double share;\n",
    "    int Array[10];\n",
    "\n",
    "    printf(\"Address of i prior to the parallel region is: %lx\\n\",(unsigned long)&i);\n",
    "    printf(\"Address of shared prior to the parallel region is: %lx\\n\",(unsigned long)&share);\n",
    "    printf(\"Address of Array prior to the parallel region is: %lx\\n\",(unsigned long)Array);\n",
    "\n",
    "    #pragma omp parallel private(i, Array) shared(share)\n",
    "    {\n",
    "        printf(\"Address of i as seen by thread %d: %lx\\n\", omp_get_thread_num(), (unsigned long)&i);\n",
    "        printf(\"Address of Array as seen by thread %d: %lx\\n\", omp_get_thread_num(), (unsigned long)Array);\n",
    "        printf(\"Address of share as seen by thread %d: %lx\\n\", omp_get_thread_num(), (unsigned long)&share);\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcc -fopenmp C/memory.c -o C/memory.exe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Address of i prior to the parallel region is: 7ffe49745dbc\n",
      "Address of shared prior to the parallel region is: 7ffe49745dc0\n",
      "Address of Array prior to the parallel region is: 7ffe49745dd0\n",
      "Address of i as seen by thread 20: 7fd070d2adec\n",
      "Address of i as seen by thread 35: 7fd06951bdec\n",
      "Address of i as seen by thread 37: 7fd068519dec\n",
      "Address of i as seen by thread 26: 7fd06dd24dec\n",
      "Address of i as seen by thread 29: 7fd06c521dec\n",
      "Address of i as seen by thread 36: 7fd068d1adec\n",
      "Address of i as seen by thread 23: 7fd06f527dec\n",
      "Address of Array as seen by thread 20: 7fd070d2adf0\n",
      "Address of i as seen by thread 44: 7fd064d12dec\n",
      "Address of i as seen by thread 34: 7fd069d1cdec\n",
      "Address of i as seen by thread 0: 7ffe49745d2c\n",
      "Address of i as seen by thread 8: 7fd076d36dec\n",
      "Address of i as seen by thread 32: 7fd06ad1edec\n",
      "Address of i as seen by thread 47: 7fd06350fdec\n",
      "Address of Array as seen by thread 26: 7fd06dd24df0\n",
      "Address of Array as seen by thread 36: 7fd068d1adf0\n",
      "Address of share as seen by thread 36: 7ffe49745dc0\n",
      "Address of i as seen by thread 4: 7fd078d3adec\n",
      "Address of i as seen by thread 3: 7fd07953bdec\n",
      "Address of i as seen by thread 12: 7fd074d32dec\n",
      "Address of Array as seen by thread 44: 7fd064d12df0\n",
      "Address of i as seen by thread 19: 7fd07152bdec\n",
      "Address of i as seen by thread 6: 7fd077d38dec\n",
      "Address of Array as seen by thread 37: 7fd068519df0\n",
      "Address of i as seen by thread 15: 7fd07352fdec\n",
      "Address of share as seen by thread 20: 7ffe49745dc0\n",
      "Address of i as seen by thread 22: 7fd06fd28dec\n",
      "Address of Array as seen by thread 34: 7fd069d1cdf0\n",
      "Address of i as seen by thread 43: 7fd065513dec\n",
      "Address of i as seen by thread 28: 7fd06cd22dec\n",
      "Address of Array as seen by thread 8: 7fd076d36df0\n",
      "Address of Array as seen by thread 19: 7fd07152bdf0\n",
      "Address of Array as seen by thread 32: 7fd06ad1edf0\n",
      "Address of share as seen by thread 37: 7ffe49745dc0\n",
      "Address of i as seen by thread 17: 7fd07252ddec\n",
      "Address of share as seen by thread 44: 7ffe49745dc0\n",
      "Address of share as seen by thread 34: 7ffe49745dc0\n",
      "Address of i as seen by thread 25: 7fd06e525dec\n",
      "Address of share as seen by thread 19: 7ffe49745dc0\n",
      "Address of Array as seen by thread 6: 7fd077d38df0\n",
      "Address of share as seen by thread 6: 7ffe49745dc0\n",
      "Address of Array as seen by thread 29: 7fd06c521df0\n",
      "Address of i as seen by thread 16: 7fd072d2edec\n",
      "Address of i as seen by thread 7: 7fd077537dec\n",
      "Address of Array as seen by thread 3: 7fd07953bdf0\n",
      "Address of Array as seen by thread 0: 7ffe49745d30\n",
      "Address of share as seen by thread 0: 7ffe49745dc0\n",
      "Address of Array as seen by thread 15: 7fd07352fdf0\n",
      "Address of i as seen by thread 40: 7fd066d16dec\n",
      "Address of i as seen by thread 18: 7fd071d2cdec\n",
      "Address of i as seen by thread 11: 7fd075533dec\n",
      "Address of Array as seen by thread 28: 7fd06cd22df0\n",
      "Address of share as seen by thread 32: 7ffe49745dc0\n",
      "Address of Array as seen by thread 47: 7fd06350fdf0\n",
      "Address of share as seen by thread 8: 7ffe49745dc0\n",
      "Address of share as seen by thread 29: 7ffe49745dc0\n",
      "Address of Array as seen by thread 16: 7fd072d2edf0\n",
      "Address of Array as seen by thread 25: 7fd06e525df0\n",
      "Address of Array as seen by thread 12: 7fd074d32df0\n",
      "Address of i as seen by thread 10: 7fd075d34dec\n",
      "Address of i as seen by thread 42: 7fd065d14dec\n",
      "Address of Array as seen by thread 4: 7fd078d3adf0\n",
      "Address of Array as seen by thread 23: 7fd06f527df0\n",
      "Address of share as seen by thread 47: 7ffe49745dc0\n",
      "Address of i as seen by thread 14: 7fd073d30dec\n",
      "Address of share as seen by thread 26: 7ffe49745dc0\n",
      "Address of Array as seen by thread 11: 7fd075533df0\n",
      "Address of share as seen by thread 16: 7ffe49745dc0\n",
      "Address of share as seen by thread 25: 7ffe49745dc0\n",
      "Address of Array as seen by thread 42: 7fd065d14df0\n",
      "Address of share as seen by thread 12: 7ffe49745dc0\n",
      "Address of share as seen by thread 3: 7ffe49745dc0\n",
      "Address of share as seen by thread 15: 7ffe49745dc0\n",
      "Address of share as seen by thread 23: 7ffe49745dc0\n",
      "Address of Array as seen by thread 17: 7fd07252ddf0\n",
      "Address of i as seen by thread 2: 7fd079d3cdec\n",
      "Address of Array as seen by thread 22: 7fd06fd28df0\n",
      "Address of i as seen by thread 39: 7fd067517dec\n",
      "Address of share as seen by thread 42: 7ffe49745dc0\n",
      "Address of Array as seen by thread 18: 7fd071d2cdf0\n",
      "Address of i as seen by thread 13: 7fd074531dec\n",
      "Address of Array as seen by thread 2: 7fd079d3cdf0\n",
      "Address of i as seen by thread 24: 7fd06ed26dec\n",
      "Address of share as seen by thread 18: 7ffe49745dc0\n",
      "Address of Array as seen by thread 40: 7fd066d16df0\n",
      "Address of Array as seen by thread 13: 7fd074531df0\n",
      "Address of share as seen by thread 13: 7ffe49745dc0\n",
      "Address of share as seen by thread 28: 7ffe49745dc0\n",
      "Address of Array as seen by thread 7: 7fd077537df0\n",
      "Address of Array as seen by thread 24: 7fd06ed26df0\n",
      "Address of share as seen by thread 24: 7ffe49745dc0\n",
      "Address of share as seen by thread 11: 7ffe49745dc0\n",
      "Address of share as seen by thread 40: 7ffe49745dc0\n",
      "Address of i as seen by thread 41: 7fd066515dec\n",
      "Address of share as seen by thread 7: 7ffe49745dc0\n",
      "Address of share as seen by thread 4: 7ffe49745dc0\n",
      "Address of Array as seen by thread 39: 7fd067517df0\n",
      "Address of Array as seen by thread 41: 7fd066515df0\n",
      "Address of share as seen by thread 41: 7ffe49745dc0\n",
      "Address of share as seen by thread 39: 7ffe49745dc0\n",
      "Address of Array as seen by thread 10: 7fd075d34df0\n",
      "Address of share as seen by thread 10: 7ffe49745dc0\n",
      "Address of share as seen by thread 2: 7ffe49745dc0\n",
      "Address of share as seen by thread 17: 7ffe49745dc0\n",
      "Address of i as seen by thread 45: 7fd064511dec\n",
      "Address of Array as seen by thread 45: 7fd064511df0\n",
      "Address of share as seen by thread 45: 7ffe49745dc0\n",
      "Address of Array as seen by thread 43: 7fd065513df0\n",
      "Address of share as seen by thread 43: 7ffe49745dc0\n",
      "Address of i as seen by thread 9: 7fd076535dec\n",
      "Address of Array as seen by thread 9: 7fd076535df0\n",
      "Address of share as seen by thread 9: 7ffe49745dc0\n",
      "Address of i as seen by thread 27: 7fd06d523dec\n",
      "Address of Array as seen by thread 27: 7fd06d523df0\n",
      "Address of share as seen by thread 27: 7ffe49745dc0\n",
      "Address of i as seen by thread 1: 7fd07a53ddec\n",
      "Address of Array as seen by thread 1: 7fd07a53ddf0\n",
      "Address of share as seen by thread 1: 7ffe49745dc0\n",
      "Address of i as seen by thread 5: 7fd078539dec\n",
      "Address of Array as seen by thread 5: 7fd078539df0\n",
      "Address of share as seen by thread 5: 7ffe49745dc0\n",
      "Address of i as seen by thread 38: 7fd067d18dec\n",
      "Address of Array as seen by thread 38: 7fd067d18df0\n",
      "Address of share as seen by thread 38: 7ffe49745dc0\n",
      "Address of i as seen by thread 33: 7fd06a51ddec\n",
      "Address of Array as seen by thread 33: 7fd06a51ddf0\n",
      "Address of share as seen by thread 33: 7ffe49745dc0\n",
      "Address of Array as seen by thread 35: 7fd06951bdf0\n",
      "Address of share as seen by thread 35: 7ffe49745dc0\n",
      "Address of i as seen by thread 21: 7fd070529dec\n",
      "Address of Array as seen by thread 21: 7fd070529df0\n",
      "Address of share as seen by thread 21: 7ffe49745dc0\n",
      "Address of i as seen by thread 31: 7fd06b51fdec\n",
      "Address of Array as seen by thread 31: 7fd06b51fdf0\n",
      "Address of share as seen by thread 31: 7ffe49745dc0\n",
      "Address of share as seen by thread 22: 7ffe49745dc0\n",
      "Address of Array as seen by thread 14: 7fd073d30df0\n",
      "Address of share as seen by thread 14: 7ffe49745dc0\n",
      "Address of i as seen by thread 30: 7fd06bd20dec\n",
      "Address of Array as seen by thread 30: 7fd06bd20df0\n",
      "Address of share as seen by thread 30: 7ffe49745dc0\n",
      "Address of i as seen by thread 46: 7fd063d10dec\n",
      "Address of Array as seen by thread 46: 7fd063d10df0\n",
      "Address of share as seen by thread 46: 7ffe49745dc0\n"
     ]
    }
   ],
   "source": [
    "!srun -N 1 C/./memory.exe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can play with this code going to [parallel.c](C/parallel.c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Private memory allows for variables to be visible only by the current worker. Shared memory, allow variables to be visible from and modified by multiple workers (read and write). However, it is important to be careful. As previously mentioned, memory organization is complex, and requires additional coordination.\n",
    "\n",
    "Take for example the following program:\n",
    "\n",
    "```C\n",
    "int main() {\n",
    "    int i = 0;\n",
    "\n",
    "    #pragma omp parallel shared(i) num_threads(10000)\n",
    "    {\n",
    "        i++;\n",
    "    }\n",
    "    \n",
    "    printf(\"i = %d\\n\",i);\n",
    "    return 0;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcc -fopenmp C/datarace.c -o C/datarace.exe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 9902\n"
     ]
    }
   ],
   "source": [
    "!srun -N 1 C/./datarace.exe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If 10000 workers are created, and each is adding 1 to the value of i, the \"expected\" value would be 10000. If you're running this in a machine that has multiple threads, I expect you to see a number less than 10000. Moreover, multiple executions may lead to different results. This is what is known as a **data race**. It occurs because reading i, incrementing, and writting to i are three different instructions. Therefore, it is possible for two threads to write the same value of i, increment it and obtain the same value twice.\n",
    "\n",
    "For this reason, shared memory requires additional coordination between workers, such that reads and writes to the same region are perceived in the expected order.\n",
    "\n",
    "Notice that this is part of thinking about **Workers/resource communication and coordination**. We are coordinating memory acesses and operations to variables, as they are shared across different workers.\n",
    "\n",
    "You can modify the above code going to [datarace.c](C/datarace.c)\n",
    "\n",
    "```\n",
    "Note: Data races are a difficult aspect of parallel programming. Multiple executions may lead to different results, but among the different results that can be obtained, it is still possible to obtain the \"expected\" result. Some data races are more difficult to debug than others, because they have a higher chance of choosing the \"expected\" result. Imagine that 1 out of a million executions of your code in a given hardware shows a datarace. Now imagine this program running the automatic pilot of an airplane...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atomic operations\n",
    "\n",
    "Atomic operations allows different threads to perform different operations to the same memory location in a single instruction (or as if they were executed in a single instruction). In the example above, atomic operations would allow for read, increment and write to happen in a single instruction (or \"atomically\"). Thus, atomic operations can solve the datarace issue of the previous example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```C\n",
    "int main() {\n",
    "    int i = 0;\n",
    "\n",
    "    #pragma omp parallel shared(i) num_threads(10000)\n",
    "    {\n",
    "        #pragma omp atomic\n",
    "        i++;\n",
    "    }\n",
    "    \n",
    "    printf(\"i = %d\\n\",i);\n",
    "    return 0;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcc -fopenmp C/atomic.c -o C/atomic.exe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 10000\n"
     ]
    }
   ],
   "source": [
    "!srun -N 1 C/./atomic.exe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can play with the above code going to [atomic.c](C/atomic.c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Private vs Firstprivate\n",
    "\n",
    "Privatization of variables means that a single variable name will have different memory locations. Privatization does not guarantee that the new address has the same value of the original address (i.e. the address before the parallel region). \n",
    "\n",
    "Take for example the following code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```C\n",
    "int main() {\n",
    "    int i = 999;\n",
    "\n",
    "    #pragma omp parallel private(i) num_threads(10)\n",
    "    {\n",
    "        print(\"Thread %d sees %d\", omp_get_thread_num(), i);\n",
    "    }\n",
    "\n",
    "    return 0;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcc -fopenmp C/private.c -o C/private.exe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 999 before parallel region\n",
      "Thread 0 sees 0 on memory 7ffe29cf4b84\n",
      "Thread 1 sees 0 on memory 7fc0f4997e14\n",
      "Thread 4 sees 0 on memory 7fc0f3194e14\n",
      "Thread 9 sees 0 on memory 7fc0f098fe14\n",
      "Thread 2 sees 0 on memory 7fc0f4196e14\n",
      "Thread 3 sees 0 on memory 7fc0f3995e14\n",
      "Thread 6 sees 0 on memory 7fc0f2192e14\n",
      "Thread 8 sees 0 on memory 7fc0f1190e14\n",
      "Thread 7 sees 0 on memory 7fc0f1991e14\n",
      "Thread 5 sees 0 on memory 7fc0f2993e14\n"
     ]
    }
   ],
   "source": [
    "!srun -N 1 C/./private.exe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can play with the above code going to [private.c](C/private.c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstprivate allows for each new address location to be initialized with the value prior to the parallel region. Take for example the following code.\n",
    "\n",
    "```C\n",
    "int main() {\n",
    "    int i[3] = {999,888,666};\n",
    "\n",
    "    printf(\"i is [%d,%d,%d] before parallel region\\n\",i[0],i[1],i[2]);\n",
    "\n",
    "    #pragma omp parallel firstprivate(i) num_threads(10)\n",
    "    {\n",
    "        printf(\"Thread %d sees [%d,%d,%d] on memory %lx\\n\", omp_get_thread_num(), i[0],i[1],i[2], (unsigned long)i);\n",
    "    }\n",
    "\n",
    "    return 0;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcc -fopenmp C/firstprivate.c -o C/firstprivate.exe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is [999,888,666] before parallel region\n",
      "Thread 0 sees [999,888,666] on memory 7ffea1df150c\n",
      "Thread 3 sees [999,888,666] on memory 7f30c661edfc\n",
      "Thread 2 sees [999,888,666] on memory 7f30c6e1fdfc\n",
      "Thread 7 sees [999,888,666] on memory 7f30c461adfc\n",
      "Thread 4 sees [999,888,666] on memory 7f30c5e1ddfc\n",
      "Thread 1 sees [999,888,666] on memory 7f30c7620dfc\n",
      "Thread 5 sees [999,888,666] on memory 7f30c561cdfc\n",
      "Thread 8 sees [999,888,666] on memory 7f30c3e19dfc\n",
      "Thread 9 sees [999,888,666] on memory 7f30c3618dfc\n",
      "Thread 6 sees [999,888,666] on memory 7f30c4e1bdfc\n"
     ]
    }
   ],
   "source": [
    "!srun -N 1 C/./firstprivate.exe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can play with the above code going to [firstprivate.c](C/firstprivate.c)\n",
    "\n",
    "Notice how each location for i is different on each thread, yet, all have the same expected value. This also means that memory copies need to be performed in order to achieve this behavior. Hence, if your array is large, it may incur in additional overhead.\n",
    "\n",
    "There are still a lot of good reasons to privatize variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reductions\n",
    "\n",
    "So far we have discussed what happens to variables when going from a sequential region to a parallel region. However, what happens to these multiple private memory locations when a parallel region is over? In principle, private variables are discarded (freed) at the end of a parallel region, hence, if their value are important, it is necessary to store them into a shared location that lives after the parallel region. Yet, it is often desireable to update the original memory location of the variable.\n",
    "\n",
    "But wait, all of these variables may have different values. How do I decide what's the final value to be used after the parallel region? Reductions are collective operations that aggregate the different values into a single value, by applying an operation. Ideally, this operation should be commutative, otherwise, how do I decide the order in which they are applied?\n",
    "\n",
    "```\n",
    "Note: Surprisingly enough OpenMP used to support the minus (-) operation for reductions. It wasn't until version 5.2 that they removed support for this operation. If thread 1 and thread 2 are reducing A, should it be At1 - At2 or At2 - At1?\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take for example the following code:\n",
    "\n",
    "```C\n",
    "int main() {\n",
    "    int i = 99;\n",
    "\n",
    "    printf(\"Value if i prior to parallel region is %d\\n\",i);\n",
    "\n",
    "    // Private values are not transferred back\n",
    "    #pragma omp parallel private(i)\n",
    "    {\n",
    "        i=1000;\n",
    "    }\n",
    "    printf(\"Value if i after parallel region with private(i) is %d\\n\",i);\n",
    "\n",
    "    i = 0;\n",
    "    // Reductions for addition.\n",
    "    #pragma omp parallel reduction(+:i) num_threads(10)\n",
    "    {\n",
    "        i=1;\n",
    "    }\n",
    "    printf(\"Value if i after parallel region with reduction(+:i) is %d\\n\",i);\n",
    "\n",
    "    // Reductions for max.\n",
    "    #pragma omp parallel reduction(max:i) num_threads(20)\n",
    "    {\n",
    "        i=omp_get_thread_num();\n",
    "    }\n",
    "    printf(\"Value if i after parallel region with reduction(max:i) is %d\\n\",i);\n",
    "\n",
    "    return 0;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcc -fopenmp C/reductions.c -o C/reductions.exe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value if i prior to parallel region is 99\n",
      "Value if i after parallel region with private(i) is 99\n",
      "Value if i after parallel region with reduction(+:i) is 10\n",
      "Value if i after parallel region with reduction(max:i) is 19\n"
     ]
    }
   ],
   "source": [
    "!srun -N 1 C/./reductions.exe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can play with the above code going to [reductions.c](C/reductions.c). Other reduction operations are:\n",
    "* Multiplication (*)\n",
    "* Minimun (min)\n",
    "* Bitwise AND (&)\n",
    "* Bitwise OR (|)\n",
    "* Bitwise XOR (^)\n",
    "* Logic AND (&&)\n",
    "* Logic OR (&&)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lastprivate\n",
    "\n",
    "Finally, there is lastprivate. Later on we will discuss more about loops and how to distribute them across workers. However, lastprivate allows for the value to be the last value in the iteration space. This means, if we have 10 iterations in a for loop, the value for i = 9 will be copied over.\n",
    "\n",
    "This code shows this behavior. Let us ignore for now the `for` construct. We will go back to it later on.\n",
    "\n",
    "```C\n",
    "    int Array[10];\n",
    "    int i, b;\n",
    "\n",
    "    for (i = 0; i < 10; i++) {\n",
    "        Array[i] = i;\n",
    "    }\n",
    "\n",
    "    #pragma omp parallel for lastprivate(b)\n",
    "    for (i = 0; i < 10; i++)\n",
    "    {\n",
    "        b = Array[i];\n",
    "    }\n",
    "    printf(\"b is %d after the parallel region\\n\", b);\n",
    "\n",
    "    return 0;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcc -fopenmp C/lastprivate.c -o C/lastprivate.exe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b is 9 after the parallel region\n"
     ]
    }
   ],
   "source": [
    "!srun -N 1 C/./lastprivate.exe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can play with this code going to [lastprivate.c](C/lastprivate.c)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "Create a program that:\n",
    "1. Initializes an array of 100 elements to random numbers by assigning a thread per element of the array. \n",
    "2. Finds the max value of the array. \n",
    "3. Finds the min value of the array.\n",
    "4. Finds the average value of the array.\n",
    "\n",
    "Go to [exercise2.c](Exercises/exercise2.c) and use the code region below to build and execute your code\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcc -fopenmp Exercises/exercise2.c -o Exercises/exercise2.exe && srun -N 1 Exercises/./exercise2.exe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See a [possible solution to Exercise 2](Solutions/exercise2.c)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9383  492  886  2777  6649  2362  8690  540  7763  9172  3926  6915  7793  8335  5386  1421  2567  59  27  5782  5736  5211  3426  5368  1530  6429  2862  5123  4067  3135  3929  9802  4022  3058  3069  1393  8167  8456  5011  8042  6229  7373  4421  4919  3784  8537  5198  4324  8315  4370  6413  3526  6091  8980  9956  1873  6862  6327  925  7281  6996  9170  2305  7084  336  6505  846  1729  1313  5857  6124  3895  9582  545  8814  3367  5434  364  4043  3750  1087  6808  7276  7178  5788  3584  5403  2651  2754  2399  9932  5060  9676  3368  7739  12  6226  8586  7539  8094 ]\n",
      "max is 9802\n",
      "min is 27\n",
      "Avg is 2311\n"
     ]
    }
   ],
   "source": [
    "!gcc -fopenmp Solutions/exercise2.c -o Solutions/exercise2.exe && srun -N 1 Solutions/./exercise2.exe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
